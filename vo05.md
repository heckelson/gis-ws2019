WH Syntax:

* Wissensbasis und Anfragen
* Implikation, Disjunktion, Konjunktion, Negation

```prolog
woman(mia).
woman(jody).
...

```

Terme werden verglichen durch Unifikation. Man kann Variablen mit Konstanten unifizieren.  
Proof Search im Hintergrund (Suchbaumstruktur). Kein Ergebnis -> falsche Aussage.  
Rekursive Definitionen sind auch möglich. Wichtig bei der Rekursion ist ein Rekursionsabschluss **vor** der Rekursionsdefinition. 

# Listen

Listen sind finite Sequenzen von Elementen.

Eckige Klammern verwenden: []

Listen haben einen head (Kopf) und einen tail (Rest der Liste).

```prolog
[mia, vincent, jules, yolanda]

% mia = head
% vincent, jules, yolanda = tail
```

leere Listen haben keine innere Struktur

HÆD

## Operator |

Mit dem Operator | kann man den head vom tail trennen. Quasi die Liste köpfen.

```prolog
?- [Head | Tail] = [mia, vincent, jules, yolanda]
> Head = mia
> Tail = [vincent, jules, yolanda]
> yes
```

Wenn der Operator verwendet wird, um eine leere Liste zu teilen, gibt Prolog 'no' zurück.

```prolog
?- [X | Y] = []
> no
```

Interessiert man sich für einige Elemente in der Liste, kann man den Head Teil ändern.

```prolog
?- [X,Y | Z] = [something]
% gibt die ersten Elemente aus (erste Ebene)

```

## Anonyme Variable _

```prolog
?- [_,X,_,Y] = [something]
% gibt jedes zweite Element aus

```

Beispiel für Listen:

```prolog
% Angenommen wir haben eine Liste [mia, vincent].
% Mit dem Operator | können wir Sachen aus einer Liste extrahieren.

?- [X | Y] = [mia, vincent]
> X = mia
> Y = [vincent]

?- [X | Y] = [mia, vincent, laura]
> X = mia
> Y = [vincent, laura]

% man kann aber andere Abfragen machen:
?- [X,Y | Z] = [mia, vincent, laura]
> X = mia
> Y = vincent
> [laura]

% Anonyme Variablen = es interessiert uns nicht.
?- [_,_ | Z] = [mia, vincent, laura]
> [laura]

% der Tail vom dritten Element:
?- [_, _, [_,X] | _] = [[], dead(zed), [2,y,a], brah]
> [y,a]

```

## member() Funktion

Ist etwas ein Element einer Liste?

```prolog

member(X,[X|T]). % nur wenn X der head ist, ist das wahr.
member(X,[H|T]) :- member(X|T).

% jetzt eine Abfrage:
?- member(vincent,[yolanda,trudy,vincent,jules]).

% Die Liste wird immer weiter verkürzt bis gefunden.
% zuerst member(X, [yolanda, trudy, vincent, jules]).
% dann member(X, [trudy, vincent, jules]).
% dann member(X, [vincent, jules]).
> yes

```

bis hierher testrelevant.

----

# Neuronale Netze

MNIST Dataset: geschriebene Zahlen erkennen:  
28x28 pixel große Bilder. Ein System, das beliebige andere Zahlen erkennt.

Man hat Trainingsdaten, die vorgegeben sind. Daraus soll dann das System lernen, Zahlen außerhalb des Trainingssets zu erkennen.

Cost: Ungenauigkeit
Valid Accuracy: Prozent der Genauigkeit (validiert durch Validierungsdaten)

Die Trainingsdaten sind 28x28px Bilder und die Werte dazu. Ein Teil der Trainingsdaten ist nur zur Validierung.

Training dataset (Bilder) -> labels (Zahlenwerte)

## Soft Computing

* Probleme in der Nachvollziehbarkeit
* Parallel
* Fuzzy logic, Multivalued logic
* Neuronale Netze
* Algorithmen entwickeln sich weiter

Beispiele für Soft computing:

* Fuzzy logic
* Evolutionary computation
* Probabilistic reasoning
* neural networks

## Anwendungen

* Klassifizierung (pattern recognition, sequence recognition)
* Prediction (Vorhersagen, historische Entwicklung anschauen und prognostizieren)
* Control (Regeltechnik, Roboter oder Drohnen)
* Data processing (Filterung, Kompression, enhancement, Rausch-Reduzierung)
* Decision making (game playing)
* Art (Google deep dream)

## Historische Entwicklung, Motivation

Neurobiologie, Neurophysiologie, Psychologie  
Gibt es Möglichkeiten, menschliche Gehirnstrukturen (kognitive Fähigkeiten) nachzubilden?

Das biologische Neuron:

* Dendriten (Signale werden über die Dendriten in den/aus dem Zellkörper transportiert)
* Synapsen (Kommunikation zwischen den Neuronen)
* Zellkörper (biochemische Reaktionen)

Konnektivität: durch große Vernetzung komplexe Aktionen möglich

### Artificial Neural Networks

Knoten, die alle miteinander verbunden sind: Massively parallel connected networks  
Parallelität zwischen Knoten, aber alle sind miteinander verbunden.

Diese Ideen wurden modelliert, relativ einfach im Vergleich zur Realität.

### Neural Network Modelle

* Feed-forward Netzwerke
  * Knoten, die in mehreren Schichten verbunden sind (hierarchisch)
* _Convolutional Networks_
* _Recurrent Networks_


### Biologisches vs. künstliches Neuron

die Kanten (Verbindungen zwischen Neuronen) werden gewichtet. Durch das Verändern der Gewichte "lernt" das Netz.

Beispiel für einen Knoten:

* Knoten j
* 3 vorhergehende Knoten o1, o2, o3
* Kanten ausgehend von den Knoten, gewichtet mit w1j, w2j, w3j.
* die Inputs alles vorhergehenden Knoten ist der net-Input (bei 28x28px: Vektor mit 784 Zeilen).

